"""Candidate pair data structures for harmonization.

Defines the output format for questionnaire harmonization workflows,
enabling export to human review applications.
"""

from __future__ import annotations

import csv
import json
from dataclasses import asdict, dataclass, field
from pathlib import Path


@dataclass
class CandidatePair:
    """A candidate match pair for human review.

    Represents a potential mapping between two items (questions or
    question-to-LOINC/HPO/MONDO) identified through vector similarity search
    or LLM-based mapping (GenOMA).

    Attributes:
        source_id: ID of the source entity.
        source_text: Text of the source entity.
        source_metadata: Metadata from source entity.
        target_id: ID of the target entity.
        target_text: Text of the target entity.
        target_metadata: Metadata from target entity.
        similarity_score: Cosine similarity score (0-1) or LLM confidence.
        match_tier: Which text variant matched ("primary", "synonym", "variation").
        harmonization_pathway: Type of harmonization ("direct_q2q", "q2loinc", "q2hpo", "q2mondo").
        loinc_code: LOINC code if Q2LOINC mapping, None for Q2Q/Q2HPO/Q2MONDO.
        confidence_level: Confidence classification ("high", "medium", "low").
        hpo_code: HPO code if Q2HPO mapping via GenOMA, None otherwise.
        mondo_code: MONDO code if Q2MONDO mapping, None otherwise.
        llm_confidence: LLM confidence score for GenOMA mappings (0-1).
        semantic_reasoning: Extracted terms or reasoning from LLM.
        extracted_terms: Medical terms extracted by GenOMA.
        match_quality: Review status ("auto_accept", "needs_review", "rejected").
        llm_processed: Whether this pair was processed via LLM (GenOMA).
    """

    source_id: str
    source_text: str
    source_metadata: dict
    target_id: str
    target_text: str
    target_metadata: dict
    similarity_score: float
    match_tier: str = "primary"
    harmonization_pathway: str = "direct_q2q"
    loinc_code: str | None = None
    confidence_level: str = "medium"
    # HPO/LLM fields for GenOMA integration
    hpo_code: str | None = None
    # MONDO disease ontology field
    mondo_code: str | None = None
    llm_confidence: float = 0.0
    semantic_reasoning: str = ""
    extracted_terms: list[str] = field(default_factory=list)
    match_quality: str = "pending"  # auto_accept | needs_review | rejected | pending
    llm_processed: bool = False

    def to_dict(self) -> dict:
        """Convert to dictionary for serialization."""
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict) -> CandidatePair:
        """Create from dictionary.

        Handles conversion of extracted_terms from JSON array format.
        """
        # Ensure extracted_terms is a list
        extracted = data.get("extracted_terms", [])
        if isinstance(extracted, str):
            # Handle case where it was serialized as comma-separated string
            extracted = [t.strip() for t in extracted.split(",") if t.strip()]
        data["extracted_terms"] = extracted if extracted else []
        return cls(**data)

    @property
    def is_high_confidence(self) -> bool:
        """Check if this is a high-confidence match."""
        return self.confidence_level == "high"

    @property
    def is_loinc_mapping(self) -> bool:
        """Check if this is a Q2LOINC mapping."""
        return self.loinc_code is not None or self.harmonization_pathway == "q2loinc"

    @property
    def is_hpo_mapping(self) -> bool:
        """Check if this is a Q2HPO mapping (via GenOMA)."""
        return self.hpo_code is not None or self.harmonization_pathway == "q2hpo"

    @property
    def is_mondo_mapping(self) -> bool:
        """Check if this is a Q2MONDO mapping."""
        return self.mondo_code is not None or self.harmonization_pathway == "q2mondo"

    @property
    def is_llm_mapping(self) -> bool:
        """Check if this mapping was generated by LLM (GenOMA)."""
        return self.llm_processed


@dataclass
class CandidatePairDataset:
    """Collection of candidate pairs for review.

    Provides methods for filtering, statistics, and export to
    various formats for human review.

    Attributes:
        pairs: List of candidate pairs.
        metadata: Dataset metadata (generation date, parameters, etc.).
    """

    pairs: list[CandidatePair] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)

    def add(self, pair: CandidatePair) -> None:
        """Add a candidate pair to the dataset."""
        self.pairs.append(pair)

    def filter_by_confidence(self, level: str) -> list[CandidatePair]:
        """Get pairs of a specific confidence level."""
        return [p for p in self.pairs if p.confidence_level == level]

    def filter_by_pathway(self, pathway: str) -> list[CandidatePair]:
        """Get pairs of a specific harmonization pathway."""
        return [p for p in self.pairs if p.harmonization_pathway == pathway]

    def filter_by_score(
        self,
        min_score: float = 0.0,
        max_score: float = 1.0,
    ) -> list[CandidatePair]:
        """Get pairs within a similarity score range."""
        return [p for p in self.pairs if min_score <= p.similarity_score <= max_score]

    @property
    def statistics(self) -> dict:
        """Compute dataset statistics."""
        if not self.pairs:
            return {"total": 0}

        scores = [p.similarity_score for p in self.pairs]
        pathways = {}
        confidence_levels = {}

        for pair in self.pairs:
            pathways[pair.harmonization_pathway] = (
                pathways.get(pair.harmonization_pathway, 0) + 1
            )
            confidence_levels[pair.confidence_level] = (
                confidence_levels.get(pair.confidence_level, 0) + 1
            )

        return {
            "total": len(self.pairs),
            "mean_score": sum(scores) / len(scores),
            "min_score": min(scores),
            "max_score": max(scores),
            "by_pathway": pathways,
            "by_confidence": confidence_levels,
        }

    def save(self, path: Path | str, format: str = "json") -> None:
        """Save dataset to file.

        Args:
            path: Output file path.
            format: Output format ("json" or "csv").
        """
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        if format == "json":
            self._save_json(path)
        elif format == "csv":
            self._save_csv(path)
        else:
            raise ValueError(f"Unsupported format: {format}")

    def _save_json(self, path: Path) -> None:
        """Save as JSON."""
        data = {
            "metadata": {
                **self.metadata,
                "statistics": self.statistics,
            },
            "pairs": [p.to_dict() for p in self.pairs],
        }
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)

    def _save_csv(self, path: Path) -> None:
        """Save as CSV for spreadsheet review."""
        if not self.pairs:
            return

        fieldnames = [
            "source_id",
            "source_text",
            "target_id",
            "target_text",
            "similarity_score",
            "match_tier",
            "harmonization_pathway",
            "loinc_code",
            "hpo_code",
            "mondo_code",
            "confidence_level",
            "llm_confidence",
            "match_quality",
            "llm_processed",
            "semantic_reasoning",
            "source_questionnaire",
            "target_questionnaire",
        ]

        with open(path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for pair in self.pairs:
                row = {
                    "source_id": pair.source_id,
                    "source_text": pair.source_text,
                    "target_id": pair.target_id,
                    "target_text": pair.target_text,
                    "similarity_score": f"{pair.similarity_score:.4f}",
                    "match_tier": pair.match_tier,
                    "harmonization_pathway": pair.harmonization_pathway,
                    "loinc_code": pair.loinc_code or "",
                    "hpo_code": pair.hpo_code or "",
                    "mondo_code": pair.mondo_code or "",
                    "confidence_level": pair.confidence_level,
                    "llm_confidence": f"{pair.llm_confidence:.4f}" if pair.llm_processed else "",
                    "match_quality": pair.match_quality,
                    "llm_processed": str(pair.llm_processed),
                    "semantic_reasoning": pair.semantic_reasoning,
                    "source_questionnaire": pair.source_metadata.get(
                        "source_questionnaire", ""
                    ),
                    "target_questionnaire": pair.target_metadata.get(
                        "source_questionnaire", ""
                    ),
                }
                writer.writerow(row)

    def export_for_review(self, path: Path | str) -> None:
        """Export in format optimized for human review.

        Creates a CSV with columns arranged for easy review:
        source text | target text | score | action columns

        Args:
            path: Output file path (CSV format).
        """
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        fieldnames = [
            "source_text",
            "target_text",
            "similarity_score",
            "confidence_level",
            "match_quality",
            "source_id",
            "target_id",
            "loinc_code",
            "hpo_code",
            "mondo_code",
            "harmonization_pathway",
            "match_tier",
            "semantic_reasoning",
            "review_decision",
            "reviewer_notes",
        ]

        with open(path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            # Sort by confidence (high first) then by score
            sorted_pairs = sorted(
                self.pairs,
                key=lambda p: (
                    -{"high": 3, "medium": 2, "low": 1}.get(p.confidence_level, 0),
                    -p.similarity_score,
                ),
            )

            for pair in sorted_pairs:
                row = {
                    "source_text": pair.source_text,
                    "target_text": pair.target_text,
                    "similarity_score": f"{pair.similarity_score:.4f}",
                    "confidence_level": pair.confidence_level,
                    "match_quality": pair.match_quality,
                    "source_id": pair.source_id,
                    "target_id": pair.target_id,
                    "loinc_code": pair.loinc_code or "",
                    "hpo_code": pair.hpo_code or "",
                    "mondo_code": pair.mondo_code or "",
                    "harmonization_pathway": pair.harmonization_pathway,
                    "match_tier": pair.match_tier,
                    "semantic_reasoning": pair.semantic_reasoning,
                    "review_decision": "",  # Placeholder for reviewer
                    "reviewer_notes": "",  # Placeholder for reviewer
                }
                writer.writerow(row)

    @classmethod
    def load(cls, path: Path | str) -> CandidatePairDataset:
        """Load dataset from JSON file."""
        with open(path, encoding="utf-8") as f:
            data = json.load(f)

        dataset = cls(metadata=data.get("metadata", {}))
        for pair_data in data.get("pairs", []):
            dataset.add(CandidatePair.from_dict(pair_data))

        return dataset

    def __len__(self) -> int:
        """Return number of pairs."""
        return len(self.pairs)

    def __iter__(self):
        """Iterate over pairs."""
        return iter(self.pairs)
